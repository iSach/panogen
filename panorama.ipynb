{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('image1.jpg')\n",
    "img2 = cv2.imread('image2.jpg')\n",
    "img3 = cv2.imread('image3.jpg')\n",
    "\n",
    "# Create a rotation matrix that will rotate the images so that the features in the images are aligned horizontally\n",
    "M1 = cv2.getRotationMatrix2D((img1.shape[1]/2, img1.shape[0]/2), 90, 1)\n",
    "M2 = cv2.getRotationMatrix2D((img2.shape[1]/2, img2.shape[0]/2), 180, 1)\n",
    "M3 = cv2.getRotationMatrix2D((img3.shape[1]/2, img3.shape[0]/2), 270, 1)\n",
    "\n",
    "img1 = cv2.warpAffine(img1, M1, (img1.shape[1], img1.shape[0]))\n",
    "img2 = cv2.warpAffine(img2, M2, (img2.shape[1], img2.shape[0]))\n",
    "img3 = cv2.warpAffine(img3, M3, (img3.shape[1], img3.shape[0]))\n",
    "\n",
    "# Compute the perspective transformation that will map the images to a cylindrical surface\n",
    "h, w = img1.shape[:2]\n",
    "dst = cv2.getPerspectiveTransform(np.float32([[0, 0], [w, 0], [w, h], [0, h]]), np.float32([[0, 0], [w, 0], [w, h], [0, h]]))\n",
    "\n",
    "# Warp the images to the cylindrical surface\n",
    "img1 = cv2.warpPerspective(img1, dst, (w, h))\n",
    "img2 = cv2.warpPerspective(img2, dst, (w, h))\n",
    "img3 = cv2.warpPerspective(img3, dst, (w, h))\n",
    "\n",
    "# Blend the overlapping areas of the images\n",
    "panorama = cv2.addWeighted(img1, 0.5, img2, 0.5, 0)\n",
    "panorama = cv2.addWeighted(panorama, 0.5, img3, 0.5, 0)\n",
    "\n",
    "cv2.imshow('panorama', panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty array to hold the transformed images\n",
    "transformed_images = []\n",
    "\n",
    "# Loop through the images\n",
    "for image in ['image1.jpg', 'image2.jpg', 'image3.jpg']:\n",
    "    # Read the image\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the features in the image using ORB\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "\n",
    "    # Create a mask to draw the features on\n",
    "    mask = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Loop through the other images\n",
    "    for other_image in ['image1.jpg', 'image2.jpg', 'image3.jpg']:\n",
    "        if other_image == image:\n",
    "            continue\n",
    "\n",
    "        # Read the other image\n",
    "        img2 = cv2.imread(other_image)\n",
    "\n",
    "        # Convert the other image to grayscale\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect the features in the other image using ORB\n",
    "        kp2, des2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "        # Use brute force to find the matches between the two images\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(des1, des2)\n",
    "\n",
    "        # Sort the matches by distance\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        # Take the top N matches\n",
    "        N = 50\n",
    "        matches = matches[:N]\n",
    "\n",
    "        # Get the coordinates of the matches\n",
    "        pts1 = np.array([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        pts2 = np.array([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Find the transformation matrix using the matches\n",
    "        H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "\n",
    "        # Warp the image using the transformation matrix\n",
    "        img_warped = cv2.warpPerspective(img, H, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        # Add the transformed image to the list of transformed images\n",
    "        transformed_images.append(img_warped)\n",
    "\n",
    "# Combine the transformed images into a single panorama\n",
    "panorama = cv2.hconcat(transformed_images)\n",
    "\n",
    "# Save the resulting panorama\n",
    "cv2.imwrite(\"panorama.jpg\", panorama)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c2e117626dba50c6b1b13c3df5f8cd020e3b4688fec6edea3e06d08349081b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
